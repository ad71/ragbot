{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan-and-Execute\n",
    "This notebook shows how to create a 'plan-and-execute' style agent. This is heavily inspired by the Plan-and-Solve paper as well as the Baby-AGI project\n",
    "\n",
    "The idea is to come up with a multi-step plan, and then go through that plan one item at a time. After accomplishing a particular task, you can then revisit the plan and modify as appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_PROJECT'] = 'Plan-and-execute'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import base64\n",
    "import asyncio\n",
    "import platform\n",
    "import requests\n",
    "import operator\n",
    "import playwright\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "from enum import Enum\n",
    "from typing import List\n",
    "from typing import Dict\n",
    "from typing import Tuple\n",
    "from typing import Union\n",
    "from typing import Optional\n",
    "from typing import Annotated\n",
    "from typing import TypedDict\n",
    "from operator import itemgetter\n",
    "\n",
    "from IPython import display\n",
    "from IPython.display import HTML\n",
    "from IPython.display import Image\n",
    "\n",
    "from langgraph.graph import END\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.prebuilt import create_agent_executor\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.messages.ai import AIMessage\n",
    "from langchain_core.messages.chat import ChatMessage\n",
    "from langchain_core.messages.tool import ToolMessage\n",
    "from langchain_core.messages.human import HumanMessage\n",
    "from langchain_core.messages.system import SystemMessage\n",
    "from langchain_core.messages.function import FunctionMessage\n",
    "from langchain_core.prompts.image import ImagePromptTemplate\n",
    "\n",
    "from langchain_core.pydantic_v1 import Field\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "from langchain_core.runnables.graph import CurveStyle\n",
    "from langchain_core.runnables.graph import NodeColors\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.schema import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain.prompts import SystemMessagePromptTemplate\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [TavilySearchResults(max_results=3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['agent_scratchpad', 'input'] input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]} metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')]\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull('hwchase17/openai-functions-agent')\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model='gpt-4o')\n",
    "agent_runnable = create_openai_functions_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f2/g8ry38sj7mn8lt71c7y6hhr40000gn/T/ipykernel_1933/1217993498.py:1: LangGraphDeprecationWarning: create_agent_executor is deprecated as of version 0.0.44 and will be removed in a future version. Use create_react_agent instead.\n",
      "from langgraph.prebuilt import create_react_agent \n",
      "\n",
      "create_react_agent(...)\n",
      "\n",
      "  agent_executor = create_agent_executor(agent_runnable=agent_runnable, tools=tools)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'who is the winner of the US open',\n",
       " 'chat_history': [],\n",
       " 'agent_outcome': AgentFinish(return_values={'output': 'The winner of the 2023 US Open in golf is Wyndham Clark. He held off the challenge from Northern Irelandâ€™s four-time major champion to win the 123rd edition of the major by a single stroke.'}, log='The winner of the 2023 US Open in golf is Wyndham Clark. He held off the challenge from Northern Irelandâ€™s four-time major champion to win the 123rd edition of the major by a single stroke.'),\n",
       " 'intermediate_steps': [(AgentActionMessageLog(tool='tavily_search_results_json', tool_input={'query': 'winner of the US Open 2023'}, log=\"\\nInvoking: `tavily_search_results_json` with `{'query': 'winner of the US Open 2023'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"query\": \"winner of the US Open 2023\"\\n}', 'name': 'tavily_search_results_json'}}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 93, 'total_tokens': 119}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_43dfabdef1', 'finish_reason': 'function_call', 'logprobs': None}, id='run-eb419011-c81a-4293-ba74-9c46631e239c-0')]),\n",
       "   '[{\\'url\\': \\'https://www.wordplays.com/crossword-solver/winner-2023-us-open\\', \\'content\\': \\'The Crossword Solver found 30 answers to \"winner 2023 us open\", 7 letters crossword clue. The Crossword Solver finds answers to classic crosswords and cryptic crossword puzzles. Enter the length or pattern for better results. Click the answer to find similar crossword clues . A clue is required.\\'}, {\\'url\\': \\'https://www.sportingnews.com/us/golf/news/us-open-2023-live-scores-results-leaderboard/jbmxrpro5jc37drgq8e2lehn\\', \\'content\\': \"Sixth hole may be one to watch in Round 4, with the hole location for Round 4 in a pretty dangerous spot close to a bunker and a nice, thick rough.\\\\n12:15 p.m.:\\\\xa0Just past noon on the east coast, and Adam Hadwin and Abraham Ancer are set to tee off at 12:18 p.m., one of the day\\'s featured groups. He gets onto the green with a great shot at 17.\\\\n9:15 p.m.:\\\\xa0Clark\\'s trip to the bunker isn\\'t a fun one, with a terrible spot keeping him from trying for the green.\\\\n Scottie in the #USOpen:2021: T-72022: T-22023: ðŸ¤”@Lexus #LexusGolf pic.twitter.com/BCiWw5uuih\\\\n3:56 p.m.:\\\\xa0Fleetwood continues his hot start and is rocketing up the leaderboard through the front nine, moving into the top ten thanks to a birdie at the 9th.\\\\n pic.twitter.com/15389pikrX\\\\n9:36 p.m.:\\\\xa0Clark begins his trek to the 18th tee and holds a one-shot lead while McIlroy hopes for a miracle up ahead on the green.\\\\n He will have a chance to go for birdie as he begins the back-nine.\\\\n7:35 p.m.:\\\\xa0And Clark manages to save par on the ninth.\"}, {\\'url\\': \\'https://www.cnn.com/2023/06/18/golf/wyndham-clark-2023-us-open-winner-spt-intl/index.html\\', \\'content\\': \\'The American, boasting just one prior win on the PGA Tour and having never previously made the cut at the tournament, held off the challenge of Northern Irelandâ€™s four-time major champion to win the 123rd edition of the major by a single stroke.\\\\n The 34-year-old had made a historic start, shooting 62 to join American compatriot Xander Schauffele in breaking the record for the lowest single round score ever shot at a US Open, but closed with a 75, the fourth highest score of the final round, to fall to tied-fifth.\\\\n One-on-one\\\\nThe prospect of a one-on-one shootout was soon all but confirmed, as Fowler made back-to-back bogeys to sink two below eight-under overall, the score he had held after just 18 holes of the tournament.\\\\n Three times a runner-up, eight times in the top-10: the bittersweet tag of being one of the best golfers to never win a major remains stuck to the fan-favorite Californian.\\\\n The Northern Irishman dropped to his knees in anguish, but received a boost when rules officials deemed his ball broke the surface, granting him a drop in the rough ahead of the bunker.\\\\n\\'}]')]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor = create_agent_executor(agent_runnable=agent_runnable, tools=tools)\n",
    "agent_executor.invoke({'input': 'who is the winner of the US open', 'chat_history': []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlanExecute(TypedDict):\n",
    "    input: str\n",
    "    plan: List[str]\n",
    "    past_steps: Annotated[List[Tuple], operator.add]\n",
    "    response: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plan(BaseModel):\n",
    "    steps: List[str] = Field(description='different steps to follow, should be in sorted order')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner_prompt = ChatPromptTemplate.from_template(\n",
    "'''For the given objective, come up with a simple step by step plan. This plan should involve individual tasks, that if executed correctly will yield the correct answer. \n",
    "Do not add any superfluous steps. The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps. \n",
    "                                                  \n",
    "{objective}\n",
    "''')\n",
    "planner_llm = ChatOpenAI(model='gpt-4o', temperature=0)\n",
    "planner = planner_prompt | planner_llm.with_structured_output(schema=Plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Plan(steps=['Identify the current Australian Open winner.', 'Find the current hometown of the identified Australian Open winner.'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planner.invoke({'objective': 'what is the current hometown of the current Australian open winner?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinegap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
