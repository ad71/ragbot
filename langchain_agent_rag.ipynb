{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOINy1Fv+d3UGgMPIijUcDA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ad71/ragbot/blob/master/langchain_agent_rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "Here we will build reliable RAG agents using LangGraph, Groq-Llama-3 and Chroma.\n",
        "We will combine the below concepts to build the RAG Agent.\n",
        "\n",
        "1. Adaptive RAG: We have implemented the concept described in this paper build a Router for routing questions to different retrieval approaches\n",
        "\n",
        "2. Corrective RAG: We have implemented the concept described in this paper to develop a fallback mechanism to progress with when the context retrieved is irrelevant to the question asked.\n",
        "\n",
        "3. Self-RAG: We have implemented the concept described in this paper to develop a hallucination grader ie fix answers that hallucinate or doesn't address the questions asked"
      ],
      "metadata": {
        "id": "wZnfv2z4sJXJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is an Agent?\n",
        "The fundamental concept behind agents involves employing a language model to select a sequence of actions. While in chains, this sequence is hardcoded within the code. Conversely, agents utilize a language model as a reasoning engine to decide the actions to take and their order.\n",
        "\n",
        "It comprises of 3 components:\n",
        "1. planning: breaking the tasks into smaller sub-goals\n",
        "2. memory: short term (chat-history) / long term (vectorstore)\n",
        "3. tool use: it can make use of different tools to extend its capabilities\n",
        "\n",
        "Agents can be manifested using ReAct concept with LangChain or by using LangGraph.\n",
        "Tradeoffs:\n",
        "\n",
        "- **Reliability**\n",
        "    1. ReAct/LangChain Agent: Less reliable, as LLM has to make the correct decision at each step.\n",
        "    2. LangGraph: More reliable, as control flow is set and LLM has a specific job to perform at each node.\n",
        "\n",
        "- **Flexibility**\n",
        "    1. ReAct/LangChain Agent: More flexible as LLM can choose any sequence of actions.\n",
        "    2. LangGraph: Less flexible as actions are constrained by setting up the control flow at each node.\n",
        "\n",
        "- **Compatiblity with smaller LLMs**\n",
        "    1. ReAct/LangChain Agent: Worse compatiblity\n",
        "    2. LangGraph: Better Compatiblity\n",
        "\n",
        "\n",
        "## LangChain:\n",
        "Framework for developing applications powered by language models. It enables applications that:\n",
        "1. Are context-aware: connect a language model to sources of context (prompt instructions, few shot examples, content to ground its response in, etc)\n",
        "2. Reason: rely on a language model to reason (about how to answer based on provided context, what actions to take, etc)\n",
        "\n",
        "## LangGraph:\n",
        "LangGraph is a library that extends LangChain, providing cyclic computational capabilities for LLM applications. While LangChain supports defining computation chains (Directed Acyclic Graphs or DAGs), **LangGraph enables the incorporation of cycles**. This allows for more intricate, agent-like behaviours, where an LLM can be called in a loop to determine the next action to take.\n",
        "\n",
        "### Key concepts:\n",
        "1. Stateful Graph: LangGraph revolves around the concept of a stateful graph, where each node in the graph represents a step in our computation, and the graph maintains a state that is passed around and updated as the computation progresses.\n",
        "2. Nodes: Nodes are the building blocks of your LangGraph. Each node represents a function or a computation step. We define nodes to perform specific tasks, such as processing input, making decisions, or interacting with external APIs.\n",
        "3. Edges: Edges connect the nodes in your graph, defining the flow of computation. LangGraph supports conditional edges, allowing you to dynamically determine the next node to execute based on the current state of the graph.\n",
        "\n",
        "### Steps involved in creating a graph using LangGraph\n",
        "1. Define the graph state: This represents the state of the graph\n",
        "2. Create the graph\n",
        "3. Define the nodes: here we define the different functions associated with each workflow state\n",
        "4. Add nodes to the graph: here add our nodes to the graph and define the flow using edges and conditional edges\n",
        "5. Set entry and end points of the graph\n",
        "\n",
        "### Tavily search API\n",
        "Tavily search API is a search engine optimized for LLMs, aimed at efficient, quick and persistent search results. Unlike other search APIs such as Serp or Google, Tavily focuses on optimizing search for AI developers and autonomous AI agents.\n",
        "### Groq\n",
        "Groq offers high-performance AI models & API access for developers with faster inference and at lower cost than competitors\n",
        "### FastEmbed\n",
        "FastEmbed is a lightweight, fast, Python library built for embedding generation."
      ],
      "metadata": {
        "id": "ZG2_91yQuUsd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zju1UZEMsFaA"
      },
      "outputs": [],
      "source": []
    }
  ]
}