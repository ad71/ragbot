{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmKz8Kk1Z3JQFdwaIg1rrr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ad71/ragbot/blob/master/hierarchical_agent_teams.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9bQK8gsde9p3"
      },
      "outputs": [],
      "source": [
        "# each first-level agent node itself is a supervisor agent"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU langchain langchain_openai langchain_community langchain_experimental langsmith matplotlib langgraph"
      ],
      "metadata": {
        "id": "ySpkO_xLfLhv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['LANGCHAIN_API_KEY'] = userdata.get('LANGCHAIN_API_KEY')\n",
        "os.environ['TAVILY_API_KEY'] = userdata.get('TAVILY_API_KEY')\n",
        "\n",
        "# optional, add tracing in LangSmith\n",
        "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
        "os.environ['LANGCHAIN_PROJECT'] = 'Multi-Agent Collaboration'"
      ],
      "metadata": {
        "id": "jIn-em97fNIG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import operator\n",
        "import functools\n",
        "\n",
        "from langchain_core.messages import (\n",
        "    AIMessage,\n",
        "    BaseMessage,\n",
        "    ChatMessage,\n",
        "    HumanMessage,\n",
        "    FunctionMessage\n",
        ")\n",
        "\n",
        "from langgraph.graph import END, StateGraph\n",
        "from langgraph.prebuilt.tool_executor import ToolExecutor, ToolInvocation\n",
        "from langchain_core.utils.function_calling import convert_to_openai_function\n",
        "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
        "\n",
        "from langchain_core.tools import tool\n",
        "from typing import Annotated, List, Sequence, Tuple, TypedDict, Union\n",
        "from langchain_experimental.tools import PythonREPLTool\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "from langchain.agents import create_openai_functions_agent, AgentExecutor\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "from langsmith import trace"
      ],
      "metadata": {
        "id": "4wlJ2q5UfRrk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Research team tools\n",
        "The research team can use a search engine and a url scraper to find information on the web. Feel free to add additional functionality below to boost the team performance."
      ],
      "metadata": {
        "id": "tiYHEC-2guVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tavily_tool = TavilySearchResults(max_results=5)\n",
        "\n",
        "@tool\n",
        "def scrape_webpages(urls: List[str]) -> str:\n",
        "    '''Use requests and bs4 to scrape the provided webpages for detailed information'''\n",
        "    loader = WebBaseLoader(urls)\n",
        "    docs = loader.load()\n",
        "    return '\\n\\n'.join(\n",
        "        [\n",
        "            f'<Document name=\"{doc.metadata[\"title\"]}\">\\n{doc.page_content}\\n</Document>'\n",
        "            for doc in docs\n",
        "        ]\n",
        "    )"
      ],
      "metadata": {
        "id": "v4GaoyjIfTbT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Document authoring team tools\n",
        "We will give some tools for the doc writing team to use. We define some bare-bones file-access tools below\n",
        "Note that this gives the agents access to your file-system, which can be unsafe.\n",
        "We also haven't optimized the tool descriptions for performance."
      ],
      "metadata": {
        "id": "dUQ9qb1Og-tM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from tempfile import TemporaryDirectory\n",
        "from typing import Dict, Optional\n",
        "\n",
        "_TEMP_DIRECTORY = TemporaryDirectory()\n",
        "WORKING_DIRECTORY = Path(_TEMP_DIRECTORY.name)\n",
        "\n",
        "@tool\n",
        "def create_outline(\n",
        "    points: Annotated[List[str], 'List of main points or sections.'],\n",
        "    file_name: Annotated[str, 'File path to save the outline.']\n",
        ") -> Annotated[str, 'Path of the saved outline file.']:\n",
        "    '''Create and save an outline'''\n",
        "    with (WORKING_DIRECTORY / file_name).open('w') as file:\n",
        "        for i, point in enumerate(points):\n",
        "            file.write(f'{i + 1}. {point}\\n')\n",
        "    return f'Outline saved to {file_name}'\n",
        "\n",
        "@tool\n",
        "def read_document(\n",
        "    file_name: Annotated[str, 'File path to save the document.'],\n",
        "    start: Annotated[Optional[int], 'The start line. Default is 0'] = None,\n",
        "    end: Annotated[Optional[int], 'The end line. Default is None'] = None\n",
        ") -> str:\n",
        "    '''Read the specified document'''\n",
        "    with (WORKING_DIRECTORY / file_name).open('r') as file:\n",
        "        lines = file.readlines()\n",
        "    if start is not None:\n",
        "        start = 0\n",
        "    return '\\n'.join(lines[start:end])\n",
        "\n",
        "@tool\n",
        "def write_document(\n",
        "    content: Annotated[str, 'Text content to be written into the document.'],\n",
        "    file_name: Annotated[str, 'File path to save the document.'],\n",
        ") -> Annotated[str, 'Path of the saved document file.']:\n",
        "    '''Create and save a text document'''\n",
        "    with (WORKING_DIRECTORY / file_name).open('w') as file:\n",
        "        file.write(content)\n",
        "    return f'Document saved to {file_name}'\n",
        "\n",
        "@tool\n",
        "def edit_document(\n",
        "    file_name: Annotated[str, 'Path of the document to be edited.'],\n",
        "    inserts: Annotated[\n",
        "        Dict[int, str],\n",
        "        'Dictionary where key is the line number (1-indexed) and value is the text to be inserted at that line.'\n",
        "    ]\n",
        ") -> Annotated[str, 'Path of the edited document file.']:\n",
        "    '''Edit a document by inserting text at specifid line numbers'''\n",
        "    with (WORKING_DIRECTORY / file_name).open('r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    sorted_inserts = sorted(inserts.items())\n",
        "\n",
        "    for line_number, text in sorted_inserts:\n",
        "        if 1 <= line_number <= len(lines) + 1:\n",
        "            lines.insert(line_number - 1, text + '\\n')\n",
        "        else:\n",
        "            return f'Error: Line number {line_number} is out of range.'\n",
        "\n",
        "    with (WORKING_DIRECTORY / file_name).open('w') as file:\n",
        "        file.writelines(lines)\n",
        "\n",
        "    return f'Document edited and saved to {file_name}'\n",
        "\n",
        "repl = PythonREPLTool()\n",
        "@tool\n",
        "def python_repl(\n",
        "    code: Annotated[str, 'The python code to execute to generate your chart.']\n",
        "):\n",
        "    '''Use this to execute python code. If you want to see the output of a value,\n",
        "    you should print it out with `print(...)`. This is visible to the user.'''\n",
        "    try:\n",
        "        result = repl.run(code)\n",
        "    except BaseException as e:\n",
        "        return f'Failed to execute. Error: {repr(e)}'\n",
        "    return f'Successfully executed:\\n```python\\n{code}\\n```\\nStdout: {result}'"
      ],
      "metadata": {
        "id": "8MonztXcgiYY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper utilities\n",
        "We are going to create a few utility functions to make it more concise when we want to\n",
        "1. Create a worker agent\n",
        "2. Create a supervisor for the sub-graph\n",
        "\n",
        "These will simplify the graph compositional code at the end for us to it's easier to see what's going on."
      ],
      "metadata": {
        "id": "6UlCRHNknjJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Any, Callable\n",
        "\n",
        "from langchain_core.runnables import Runnable\n",
        "from langchain_core.tools import BaseTool\n",
        "\n",
        "def create_agent(llm: ChatOpenAI, tools: list, system_prompt: str) -> str:\n",
        "    '''Create a function calling agent and add it to the graph'''\n",
        "    system_prompt += '\\nWork autonomously according to your speciality, using the tools available to you.'\n",
        "    'Do not ask for clarification. '\n",
        "    'Your other team members (and other teams) will collaborate with you with their own specialities. '\n",
        "    'You are chosen for a reason! You are one of the following team members: {team_members}.'\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\n",
        "                'system',\n",
        "                system_prompt\n",
        "            ),\n",
        "            MessagesPlaceholder(variable_name='messages'),\n",
        "            MessagesPlaceholder(variable_name='agent_scratchpad')\n",
        "        ]\n",
        "    )\n",
        "    agent = create_openai_functions_agent(llm, tools, prompt)\n",
        "    executor = AgentExecutor(agent=agent, tools=tools)\n",
        "    return executor\n",
        "\n",
        "def agent_node(state, agent, name):\n",
        "    result = agent.invoke(state)\n",
        "    return {'messages': [HumanMessage(content=result['output'], name=name)]}\n",
        "\n",
        "def create_team_supervisor(llm: ChatOpenAI, system_prompt, members) -> str:\n",
        "    '''An LLM based router'''\n",
        "    options = ['FINISH'] + members\n",
        "    function_def = {\n",
        "        'name': 'router',\n",
        "        'description': 'Select the next role.',\n",
        "        'parameters': {\n",
        "            'title': 'routeSchema',\n",
        "            'type': 'object',\n",
        "            'properties': {\n",
        "                'next': {\n",
        "                    'title': 'next',\n",
        "                    'anyOf': [\n",
        "                        {'enum': options}\n",
        "                    ]\n",
        "                }\n",
        "            },\n",
        "            'required': ['next']\n",
        "        }\n",
        "    }\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            ('system', system_prompt),\n",
        "            MessagesPlaceholder(variable_name='messages'),\n",
        "            (\n",
        "                'system',\n",
        "                'Given the conversation above, who should act next? '\n",
        "                'Or should we FINISH? Select one of: {options}'\n",
        "            )\n",
        "        ]\n",
        "    ).partial(options=str(options), team_members=', '.join(members))\n",
        "    return (prompt | llm.bind_functions(functions=[function_def], function_call='router') | JsonOutputFunctionsParser())"
      ],
      "metadata": {
        "id": "rYGpX_NulnrI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Research Team\n",
        "The research team will have a search agent and a web scraping \"reseach_agent\" as the two worker nodes. Let's create those, as well as the team supervisor."
      ],
      "metadata": {
        "id": "kb2Fp5UQq-VV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResearchTeamState(TypedDict):\n",
        "    messages: Annotated[List[BaseMessage], operator.add] # a message is added after each team member finishes\n",
        "    team_members: List[str] # the team members are tracked so they are aware of the others' skill-sets\n",
        "    next: str # the supervisor calls a function that will update this every time it makes a decision\n",
        "\n",
        "llm = ChatOpenAI(model='gpt-4-1106-preview')\n",
        "\n",
        "search_agent = create_agent(llm, [tavily_tool], 'You are a research assistant who can search for up-to date info using the tavily search tool')\n",
        "search_node = functools.partial(agent_node, agent=search_agent, name='Search')\n",
        "\n",
        "research_agent = create_agent(llm, [scrape_webpages], 'You are a research assistant who can scrape specified urls for more detailed information')\n",
        "research_node = functools.partial(agent_node, agent=research_agent, name='Web Scraper')\n",
        "\n",
        "supervisor_agent = create_team_supervisor(\n",
        "    llm=llm,\n",
        "    system_prompt='You are a supervisor tasked with managing a conversation between the '\n",
        "    'following workers: Search, Web Scraper. Given the following user request, '\n",
        "    'respond with the worker to act next. Each worker will perform a '\n",
        "    'task and respond with their results and status. When finished, '\n",
        "    'respond with FINISH.',\n",
        "    members=['Search', 'Web Scraper']\n",
        ")"
      ],
      "metadata": {
        "id": "gAW-2WHZq5vQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "research_graph = StateGraph(ResearchTeamState)\n",
        "research_graph.add_node('Search', search_node)\n",
        "research_graph.add_node('Web Scraper', research_node)\n",
        "research_graph.add_node('supervisor', supervisor_agent)\n",
        "\n",
        "research_graph.add_edge('Search', 'supervisor')\n",
        "research_graph.add_edge('Web Scraper', 'supervisor')\n",
        "research_graph.add_conditional_edges(\n",
        "    'supervisor',\n",
        "    lambda x: x['next'],\n",
        "    {\n",
        "        'Search': 'Search',\n",
        "        'Web Scraper': 'Web Scraper',\n",
        "        'FINISH': END\n",
        "    }\n",
        ")\n",
        "\n",
        "research_graph.set_entry_point('supervisor')\n",
        "chain = research_graph.compile()\n",
        "\n",
        "# the following functions interoperate between the top level graph state and the state of the research sub-graph\n",
        "# this makes it so that the states of each graph don't get intermixed\n",
        "def enter_chain(message: str):\n",
        "    results = {\n",
        "        'messages': [HumanMessage(content=message)],\n",
        "    }\n",
        "    return results\n",
        "\n",
        "research_chain = enter_chain | chain"
      ],
      "metadata": {
        "id": "Xy0ecDgFsjoH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we can use this directly\n",
        "for s in research_chain.stream(\n",
        "    'When is Taylor Swift\\'s next tour?',\n",
        "    {'recursion_limit': 100}):\n",
        "    if '__end__' not in s:\n",
        "        print(s)\n",
        "        print('--------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-XsMqiWt0Gl",
        "outputId": "6c0fb926-4b85-41ee-bc9a-b2ae9c1bfed3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'supervisor': {'next': 'Search'}}\n",
            "--------\n",
            "{'Search': {'messages': [HumanMessage(content='Taylor Swift\\'s next tour, known as \"The Eras Tour,\" began in March 2023. After the initial U.S. tour dates, she is scheduled to kick off the 18-city Europe leg. Specific dates and further details about additional legs of the tour or any updates beyond what has been provided here would require checking official sources or tour announcements for the most current information.', name='Search')]}}\n",
            "--------\n",
            "{'supervisor': {'next': 'FINISH'}}\n",
            "--------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BZhcsEb0uNTc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}