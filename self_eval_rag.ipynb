{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ad71/ragbot/blob/master/self_eval_rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "A0n00YXEwBFT",
        "outputId": "f470b812-e0a3-4daa-865e-f9cc7f8925b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.30.1)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.10/dist-packages (0.1.7)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.2)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (4.2.0)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.6)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.59)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain) (2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Installing collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.8.0\n"
          ]
        }
      ],
      "source": [
        "%pip install langchain openai langchain_openai langchain_community transformers pypdf faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SDH6LphqvtO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from io import StringIO\n",
        "from collections import Counter\n",
        "from operator import itemgetter\n",
        "from enum import Enum\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_community.vectorstores import FAISS, Chroma\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
        "from langchain_community.vectorstores.faiss import DistanceStrategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_YymoYrwSoc"
      },
      "outputs": [],
      "source": [
        "pdf_filepath = '/content/sample_data/machine_learning_basics.pdf'\n",
        "loader = PyPDFLoader(pdf_filepath)\n",
        "pdf_text = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XuO-JP9xxngY"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "chunks = text_splitter.split_documents(pdf_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFmke_Mnx3ZE",
        "outputId": "01f8f7ec-8960-49cc-d3d8-6ffd67ccccee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='THE FUNDAMENTALS  \\nOF MACHINE LEARNING', metadata={'source': '/content/sample_data/machine_learning_basics.pdf', 'page': 0}),\n",
              " Document(page_content='WHAT IS MACHINE LEARNING?\\nBRIEF HISTORY OF MACHINE LEARNING\\nHOW IT WORKS\\nMACHINE LEARNING TECHNIQUES\\nTHE IMPORTANCE OF THE HUMAN ELEMENT\\nWHO’S USING IT?\\nCHALLENGES AND HESITATIONS\\nTHE FUTURE OF MACHINE LEARNING\\nCONTRIBUTORS3\\n5\\n8\\n9\\n11\\n12\\n1514\\n16TABLE OF CONTENTS\\n2', metadata={'source': '/content/sample_data/machine_learning_basics.pdf', 'page': 1}),\n",
              " Document(page_content='WHAT IS MACHINE LEARNING?\\nWhether we realize it or not, machine learning is something we \\nencounter on a daily basis. While the technology is not new, \\nwith the rise of artificial intelligence (AI) and the digital age, it is \\nbecoming increasingly important to understand what it is, how it \\ndiffers from AI, and the major role it will play in the future. This \\nwhitepaper will discuss all of the above, and explore different \\ntypes of machine learning, how they work, and how a majority', metadata={'source': '/content/sample_data/machine_learning_basics.pdf', 'page': 2}),\n",
              " Document(page_content='types of machine learning, how they work, and how a majority  \\nof industries are utilizing it.\\nFirst and foremost, it’s important to understand exactly what \\nmachine learning is and how it differs from AI. In its simplest form, \\nmachine learning is a set of algorithms learned from data and/or \\nexperiences, rather than being explicitly programmed. Each task \\nrequires a different set of algorithms, and these algorithms detect \\npatterns to perform certain tasks.HOW IS IT DIFFERENT FROM', metadata={'source': '/content/sample_data/machine_learning_basics.pdf', 'page': 2}),\n",
              " Document(page_content='patterns to perform certain tasks.HOW IS IT DIFFERENT FROM  \\nARTIFICIAL INTELLIGENCE?\\nWhile the two are interconnected, machine learning and artificial \\nintelligence are different. It’s easiest to think of machine learning \\nas the underlying technology of AI.  The goal of AI is to imitate \\nand mimic human behavior, and machine learning gives us the \\nmathematical tools that allow us to do that. AI can understand \\nlanguage and conduct a conversation, allowing it to continually', metadata={'source': '/content/sample_data/machine_learning_basics.pdf', 'page': 2})]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chunks[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nxTDi3Ihx46-"
      },
      "outputs": [],
      "source": [
        "qa_prompt = ChatPromptTemplate.from_template('''\n",
        "You are an assistant for question-answering tasks.\n",
        "Use the following pieces of retrieved context to answer the question.\n",
        "If you don't know the answer, just say that you don't know.\n",
        "Use three sentences maximum and keep the answer concise.\n",
        "Question: {question}\n",
        "Context: {context}\n",
        "Answer:\n",
        "''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7f2Lo14HyXDN"
      },
      "outputs": [],
      "source": [
        "# prompt template for LLM QA self eval\n",
        "\n",
        "class gradeEnum(str, Enum):\n",
        "    correct = 'correct'\n",
        "    incorrect = 'incorrect'\n",
        "\n",
        "\n",
        "class LLMEvalResult(BaseModel):\n",
        "    grade: gradeEnum = Field(description='Final grade label. Accepted labels : Correct, Incorrect')\n",
        "    description: str = Field(description='Explanation of why the specific grade was assigned. Must be concise. Not more than 2 sentences')\n",
        "\n",
        "json_parser = JsonOutputParser(pydantic_object=LLMEvalResult)\n",
        "\n",
        "# evaluates answer based only on question\n",
        "qa_eval_prompt_text = '''\n",
        "You are a teacher evaluating a test.\n",
        "You are provided with a question along with an answer for the question written by a student. Evaluate the question-answer pair and provide feedback.\n",
        "{format_instructions}\n",
        "Question: {question}\n",
        "Answer: {answer}\n",
        "'''\n",
        "\n",
        "qa_eval_prompt = PromptTemplate(\n",
        "    template=qa_eval_prompt_text,\n",
        "    input_variables=['question', 'answer'],\n",
        "    partial_variables={'format_instructions': json_parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "# evaluates answer based on question and context\n",
        "qa_eval_prompt_with_context_text = '''\n",
        "You are a teacher evaluating a test.\n",
        "You are provided with a question along with an answer for the question written by a student. Evaluate the question-answer pair using the provided context and provide feedback. Only mark the answer as correct if it agrees with the provided context.\n",
        "\n",
        "{format_instructions}\n",
        "Context: {context}\n",
        "Question: {question}\n",
        "Answer: {answer}\n",
        "'''\n",
        "\n",
        "qa_eval_prompt_with_context = PromptTemplate(\n",
        "    template=qa_eval_prompt_text,\n",
        "    input_variables=['question', 'answer', 'context'],\n",
        "    partial_variables={'format_instructions': json_parser.get_format_instructions()}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IVx4UF5g1Mc2"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-5X6mbsyzlAX"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0)\n",
        "llm_self_eval = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "pEAt2RlE1JFU"
      },
      "outputs": [],
      "source": [
        "store = FAISS.from_documents(chunks, OpenAIEmbeddings(), distance_strategy=DistanceStrategy.COSINE)\n",
        "retriever = store.as_retriever(search_kwargs={'k': 3})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "BCo8dGR61nZb"
      },
      "outputs": [],
      "source": [
        "# utils\n",
        "def format_docs(docs):\n",
        "    return '\\n\\n ----------------'.join(doc.page_content for doc in docs)\n",
        "\n",
        "def retrieve_answer(output):\n",
        "    return output.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dhQrMYPJ1z3b"
      },
      "outputs": [],
      "source": [
        "# simple qa chain\n",
        "rag_chain = (\n",
        "    RunnableParallel(context=retriever | format_docs, question=RunnablePassthrough())\n",
        "    | qa_prompt\n",
        "    | llm\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgTv9GaU2Fck",
        "outputId": "ea3ea1a5-4767-4dae-dc18-6f56998ffb0b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Support Vector Machines (SVMs) were invented in 1992.', response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 369, 'total_tokens': 384}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-c5fe000c-7136-4ea3-b517-25b454315b02-0')"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_chain.invoke('When was SVM invented?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzaHCHjr2MGq",
        "outputId": "2ec87a4b-8261-4215-aeeb-0554eef46bd4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Support Vector Machines (SVMs) were invented in 1992.', response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 369, 'total_tokens': 384}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-07024e7e-edb1-464e-b10b-6890fe4396a2-0')"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# same RAG without LCEL\n",
        "question = 'When was SVM invented?'\n",
        "context = format_docs(retriever.invoke(question))\n",
        "prompt = qa_prompt.invoke({'question': question, 'context': context})\n",
        "answer = llm.invoke(prompt)\n",
        "\n",
        "answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bzdk3rK0Pv0p"
      },
      "source": [
        "### Self eval the RAG system by evaluating the question-answer pair. In this scenario, we do not utilize the retrieved context as part of the evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "fLrm-81T2gU8"
      },
      "outputs": [],
      "source": [
        "rag_chain = (\n",
        "    RunnableParallel(context=retriever | format_docs, question=RunnablePassthrough())\n",
        "    | RunnableParallel(answer=qa_prompt | llm | retrieve_answer, question=itemgetter('question'))\n",
        "    | RunnableParallel(evaluation=qa_eval_prompt | llm_self_eval | json_parser, answer=itemgetter('answer'))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ejWKx6tS1ow",
        "outputId": "23da93ed-819f-4955-9875-458ddacc7186"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'evaluation': {'grade': 'Correct',\n",
              "  'description': 'The answer is accurate and provides the necessary information about the invention of Support Vector Machines (SVMs) in 1992 by researchers at AT&T.'},\n",
              " 'answer': 'Support Vector Machines (SVMs) were invented in 1992 by researchers at AT&T.'}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_chain.invoke('When was SVM invented?')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUhley1lUEb8"
      },
      "source": [
        "### QA RAG with self eval II\n",
        "In addition to the question-answer pair, we also pass the retrieved context to the evaluator LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "4oCurZW5S9nF"
      },
      "outputs": [],
      "source": [
        "rag_chain = (\n",
        "    RunnableParallel(context=retriever | format_docs, question=RunnablePassthrough())\n",
        "    | RunnableParallel(answer=qa_prompt | llm | retrieve_answer, question=itemgetter('question'), context=itemgetter('context'))\n",
        "    | RunnableParallel(input=qa_eval_prompt, context=itemgetter('context'))\n",
        "    | RunnableParallel(input=itemgetter('input') | llm_self_eval, context=itemgetter('context'))\n",
        "    | RunnableParallel(input=itemgetter('input') | json_parser, context=itemgetter('context'))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxASpAM9V4Fj",
        "outputId": "5399bf2a-e73a-4ca7-9cd0-214b53863bc3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input': {'grade': 'Correct',\n",
              "  'description': 'The answer correctly states that Support Vector Machines (SVMs) were invented in 1992 by researchers at AT&T.'},\n",
              " 'context': 'learning approach called Hidden Markov Models (HMMs). This \\nsaved billions of dollars in operating costs by spotting things like \\ncollect calls.\\nSUPPORT VECTOR MACHINES  1992\\nResearchers at AT&T invented Support Vector Machines (SVMs) \\nin 1992, a technique that revolutionized large scale classification \\nbecause of its predictable performance.\\n5\\n\\n ----------------CONVOLUTIONAL NEURAL NETWORK  1996\\nPatrick Haffner (Lead Inventive Scientist at Interactions) and \\nresearchers from AT&T proposed the first convolutional neural \\nnetwork (CNN) in 1996, with a large scale application to check \\nrecognition. The influence of this technology was not appreciated \\nuntil 10 years later when it became rebranded as deep learning, and \\nmachine learning researchers began to focus on another technique \\ndeveloped by the same group at AT&T: Support Vector Machines.\\n\\n ----------------Voice Response (IVR) systems in 2001, combining 3 of its machine \\nlearning technologies: SVMs, HMMs, and Adaboost.\\nDEEP LEARNING  2006\\nThe concept of deep learning was successfully promoted, \\nincreasing the power and accuracy of neural networks.\\nDEEP NEURAL NETWORKS  2011\\nA group of researchers began to work on deep neural networks \\n(DNNs) in 2011 and new algorithms were discovered that \\nmade it possible to train a model on millions of examples,'}"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_chain.invoke('When was SVM invented?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "lns0paOyV6lt"
      },
      "outputs": [],
      "source": [
        "# more concise\n",
        "rag_chain = (\n",
        "    RunnableParallel(context=retriever | format_docs, question=RunnablePassthrough())\n",
        "    | RunnableParallel(answer=qa_prompt | llm | retrieve_answer, question=itemgetter('question'), context=itemgetter('context'))\n",
        "    | RunnableParallel(input=qa_eval_prompt | llm_self_eval | json_parser, context=itemgetter('context'))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "N_j8ZjarZBL-"
      },
      "outputs": [],
      "source": [
        "# global variable to save intermediate steps\n",
        "global context\n",
        "\n",
        "def save_context(x):\n",
        "    global context\n",
        "    context = x\n",
        "    return x\n",
        "\n",
        "rag_chain = (\n",
        "    RunnableParallel(context=retriever | format_docs | save_context, question=RunnablePassthrough())\n",
        "    | RunnableParallel(answer=qa_prompt | llm | retrieve_answer, question=itemgetter('question'))\n",
        "    | qa_eval_prompt\n",
        "    | llm_self_eval\n",
        "    | json_parser\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UE6aa9BZncB",
        "outputId": "2b4242cc-ab4c-4318-e609-5613e6f5bcf2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'grade': 'Correct',\n",
              " 'description': 'The answer correctly states that Support Vector Machines (SVMs) were invented in 1992 by researchers at AT&T.'}"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_chain.invoke('When was SVM invented?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "U-pXv5O9ZwAe",
        "outputId": "3a5a335b-5e44-4d84-900c-08a2aa5b3748"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'learning approach called Hidden Markov Models (HMMs). This \\nsaved billions of dollars in operating costs by spotting things like \\ncollect calls.\\nSUPPORT VECTOR MACHINES  1992\\nResearchers at AT&T invented Support Vector Machines (SVMs) \\nin 1992, a technique that revolutionized large scale classification \\nbecause of its predictable performance.\\n5\\n\\n ----------------CONVOLUTIONAL NEURAL NETWORK  1996\\nPatrick Haffner (Lead Inventive Scientist at Interactions) and \\nresearchers from AT&T proposed the first convolutional neural \\nnetwork (CNN) in 1996, with a large scale application to check \\nrecognition. The influence of this technology was not appreciated \\nuntil 10 years later when it became rebranded as deep learning, and \\nmachine learning researchers began to focus on another technique \\ndeveloped by the same group at AT&T: Support Vector Machines.\\n\\n ----------------Voice Response (IVR) systems in 2001, combining 3 of its machine \\nlearning technologies: SVMs, HMMs, and Adaboost.\\nDEEP LEARNING  2006\\nThe concept of deep learning was successfully promoted, \\nincreasing the power and accuracy of neural networks.\\nDEEP NEURAL NETWORKS  2011\\nA group of researchers began to work on deep neural networks \\n(DNNs) in 2011 and new algorithms were discovered that \\nmade it possible to train a model on millions of examples,'"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bd0kGp-hZwuC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPQAp3l8i+nPdJl3c+KZl5B",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
