{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflexion\n",
    "Is an architecture designed to learn through verbal feedback and self-reflection. The agent explicitly critiques its reponses for tasks to generate a higher quality final response, at the expense of longer execution time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import base64\n",
    "import asyncio\n",
    "import datetime\n",
    "import platform\n",
    "import requests\n",
    "import operator\n",
    "import playwright\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "from enum import Enum\n",
    "from typing import List\n",
    "from typing import Dict\n",
    "from typing import Tuple\n",
    "from typing import Union\n",
    "from typing import Literal\n",
    "from typing import Optional\n",
    "from typing import Sequence\n",
    "from typing import Annotated\n",
    "from typing import TypedDict\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict\n",
    "\n",
    "from IPython import display\n",
    "from IPython.display import HTML\n",
    "from IPython.display import Image\n",
    "\n",
    "from langsmith import traceable\n",
    "\n",
    "from langgraph.graph import END\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph import MessageGraph\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.prebuilt.tool_executor import ToolExecutor\n",
    "from langgraph.prebuilt.tool_executor import ToolInvocation\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "from langchain_core.tools import StructuredTool\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.messages.ai import AIMessage\n",
    "from langchain_core.messages.chat import ChatMessage\n",
    "from langchain_core.messages.tool import ToolMessage\n",
    "from langchain_core.messages.human import HumanMessage\n",
    "from langchain_core.messages.system import SystemMessage\n",
    "from langchain_core.messages.function import FunctionMessage\n",
    "from langchain_core.prompts.image import ImagePromptTemplate\n",
    "\n",
    "from langchain_core.pydantic_v1 import Field\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain_core.pydantic_v1 import ValidationError\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "from langchain_core.runnables.graph import CurveStyle\n",
    "from langchain_core.runnables.graph import NodeColors\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.schema import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain.prompts import SystemMessagePromptTemplate\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.output_parsers.openai_tools import PydanticToolsParser\n",
    "from langchain.output_parsers.openai_tools import JsonOutputToolsParser\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
    "\n",
    "from langchain_fireworks.chat_models import ChatFireworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_PROJECT'] = 'Reflexion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = TavilySearchAPIWrapper()\n",
    "tavily_tool = TavilySearchResults(api_wrapper=search, max_results=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tools are invoked _in context_. Create a function that invokes all the requested tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_prompt = '''You are an expert researcher. \n",
    "Current time: {time}\n",
    "\n",
    "1. {first_instruction}\n",
    "2. Reflect and critique your answer. Be severe to maximize improvement.\n",
    "3. Recommend search queries to research information and improve your answer.'''\n",
    "\n",
    "actor_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            'system',\n",
    "            actor_prompt\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name='messages'),\n",
    "        (\n",
    "            'user',\n",
    "            '\\n\\n<reminder>Reflect on the user\\'s original question and the actions taken thus far. Respond using the {function_name} function.</reminder>'\n",
    "        )\n",
    "    ]\n",
    ").partial(time=lambda: datetime.datetime.now().isoformat())\n",
    "\n",
    "\n",
    "class Reflection(BaseModel):\n",
    "    missing: str = Field(description='Critique of what is missing')\n",
    "    superfluous: str = Field(description='Critique of what is superfluous')\n",
    "\n",
    "\n",
    "class AnswerQuestion(BaseModel):\n",
    "    '''Answer the question'''\n",
    "    answer: str = Field(description='~250 word detailed answer to the question.')\n",
    "    reflection: Reflection = Field(description='Your reflection on the initial answer.')\n",
    "    search_queries: List[str] = Field(description='1 - 3 search queries for researching improvements to address the critique of your current answer.')\n",
    "\n",
    "\n",
    "class ResponderWithRetries:\n",
    "    def __init__(self, runnable, validator):\n",
    "        self.runnable = runnable\n",
    "        self.validator = validator\n",
    "\n",
    "    @traceable\n",
    "    def respond(self, state: List[BaseMessage]):\n",
    "        response = []\n",
    "        for attempt in range(3):\n",
    "            response = self.runnable.invoke({'messages': state}, {'tags': [f'attempt:{attempt}']})\n",
    "            try:\n",
    "                self.validator.invoke(response)\n",
    "                return response\n",
    "            except ValidationError as e:\n",
    "                print('RETRYING', attempt)\n",
    "                state = state + [\n",
    "                    response,\n",
    "                    ToolMessage(\n",
    "                        content=f'{repr(e)}\\n\\nPay close attention to the function schema.\\n\\n'\n",
    "                        + self.validator.schema_json()\n",
    "                        + ' Respond by fixing all validation errors.',\n",
    "                        tool_call_id=response.tool_calls[0]['id'],\n",
    "                    )\n",
    "                ]\n",
    "\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model='gpt-4o')\n",
    "initial_answer_chain = actor_prompt_template.partial(\n",
    "    first_instruction='Provide a detailed ~250 word answer.',\n",
    "    function_name=AnswerQuestion.__name__) | llm.bind_tools(tools=[AnswerQuestion])\n",
    "validator = PydanticToolsParser(tools=[AnswerQuestion])\n",
    "first_responder = ResponderWithRetries(runnable=initial_answer_chain, validator=validator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RETRYING 0\n"
     ]
    }
   ],
   "source": [
    "example_question = 'Why is reflection useful in AI?'\n",
    "initial = first_responder.respond([HumanMessage(content=example_question)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'args': {'answer': \"Reflection in AI refers to an AI system's ability to monitor, analyze, and adapt its own processes and performance. This capability is essential for several reasons. Firstly, it allows AI systems to improve over time. By reflecting on past actions and outcomes, an AI can identify errors, learn from them, and adjust its behavior to avoid making the same mistakes in the future. This is particularly important in dynamic environments where conditions and requirements may change rapidly. Secondly, reflection enhances the transparency and explainability of AI systems. By being able to articulate why certain decisions were made or why particular actions were taken, AI systems can provide insights into their decision-making processes. This can increase trust and acceptance among users and stakeholders. Thirdly, reflection can contribute to ethical AI development. It enables AI systems to assess the implications of their actions and ensure they align with ethical guidelines and standards. Finally, reflection supports better human-AI collaboration. By understanding and adapting to human preferences and feedback, AI systems can work more effectively alongside humans, leading to more productive and harmonious interactions.\",\n",
       "   'reflection': {'missing': 'Specific examples or case studies that illustrate the benefits of reflection in AI are missing. These would help to ground the abstract concepts in real-world applications and make the answer more compelling.',\n",
       "    'superfluous': 'Some parts of the answer may be slightly redundant, particularly the repeated emphasis on improvement and learning from past actions.'},\n",
       "   'search_queries': ['examples of reflection in AI systems',\n",
       "    'case studies on reflective AI',\n",
       "    'benefits of reflective AI in real-world applications']},\n",
       "  'id': 'call_ugMXA7EfMZi1JZHmcK43EgnC',\n",
       "  'type': 'AnswerQuestion'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JsonOutputToolsParser(return_id=True).invoke(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revision\n",
    "The second part of the actor is a revision step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "revise_instructions = '''Revise your previous answer using the new information. \n",
    "    - You should use the previous critique to add important information to your answer. \n",
    "        - You MUST include numerical citations in your revised answer to ensure it can be verified. \n",
    "        - Add a \"References\" section to the bottom of your answer (which does not count towards the word limit). In form of: \n",
    "            - [1] https://example.com\n",
    "            - [2] https://example.com\n",
    "    - You should use the previous critique to remove superfluous information from your answer and make SURE it is not more than 250 words.'''\n",
    "\n",
    "# extend the initial answer schema to include references\n",
    "# forcing citation in the model encourages grounded responses\n",
    "class ReviseAnswer(AnswerQuestion):\n",
    "    '''Revise your original answer to the question. Provide an answer, reflection, cite your reflection with references and finally add search queries to improve the answer'''\n",
    "    references: List[str] = Field(description='Citations motivating your updated answer')\n",
    "\n",
    "revision_chain = actor_prompt_template.partial(\n",
    "    first_instruction=revise_instructions,\n",
    "    function_name=ReviseAnswer.__name__) | llm.bind_tools(tools=[ReviseAnswer])\n",
    "revision_validator = PydanticToolsParser(tools=[ReviseAnswer])\n",
    "revisor = ResponderWithRetries(runnable=revision_chain, validator=revision_validator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_a7zHIQgGQSPiCwAU8PE7Dz8E', 'function': {'arguments': '{\"answer\": \"Reflection in AI refers to an AI system\\'s ability to monitor, analyze, and adapt its own processes and performance. This capability is essential for several reasons. Firstly, it allows AI systems to improve over time. By reflecting on past actions and outcomes, an AI can identify errors, learn from them, and adjust its behavior to avoid making the same mistakes in the future. This is particularly important in dynamic environments where conditions and requirements may change rapidly. Secondly, reflection enhances the transparency and explainability of AI systems. By being able to articulate why certain decisions were made or why particular actions were taken, AI systems can provide insights into their decision-making processes. This can increase trust and acceptance among users and stakeholders. Thirdly, reflection can contribute to ethical AI development. It enables AI systems to assess the implications of their actions and ensure they align with ethical guidelines and standards. Finally, reflection supports better human-AI collaboration. By understanding and adapting to human preferences and feedback, AI systems can work more effectively alongside humans, leading to more productive and harmonious interactions.\", \"reflection\": {\"missing\": \"Specific examples or case studies that illustrate the benefits of reflection in AI are missing. These would help to ground the abstract concepts in real-world applications and make the answer more compelling.\", \"superfluous\": \"Some parts of the answer may be slightly redundant, particularly the repeated emphasis on improvement and learning from past actions.\"}, \"search_queries\": [\"examples of reflection in AI systems\", \"case studies on reflective AI\", \"benefits of reflective AI in real-world applications\"], \"references\": [\"https://www.unite.ai/ais-inner-dialogue-how-self-reflection-enhances-chatbots-and-virtual-assistants/\", \"https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection/\", \"https://blog.langchain.dev/reflection-agents/\", \"https://laxfed.dev/what-are-reflection-agents-68e49f13d90b\", \"https://medium.com/stanford-d-school/reflecting-with-ai-a-tool-to-develop-human-intelligence-88cec86babf\"]}', 'name': 'ReviseAnswer'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 451, 'prompt_tokens': 1737, 'total_tokens': 2188}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_5e6c71d4a8', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-1df7bbd1-fd7e-406e-b617-e37e31b4b44d-0', tool_calls=[{'name': 'ReviseAnswer', 'args': {'answer': \"Reflection in AI refers to an AI system's ability to monitor, analyze, and adapt its own processes and performance. This capability is essential for several reasons. Firstly, it allows AI systems to improve over time. By reflecting on past actions and outcomes, an AI can identify errors, learn from them, and adjust its behavior to avoid making the same mistakes in the future. This is particularly important in dynamic environments where conditions and requirements may change rapidly. Secondly, reflection enhances the transparency and explainability of AI systems. By being able to articulate why certain decisions were made or why particular actions were taken, AI systems can provide insights into their decision-making processes. This can increase trust and acceptance among users and stakeholders. Thirdly, reflection can contribute to ethical AI development. It enables AI systems to assess the implications of their actions and ensure they align with ethical guidelines and standards. Finally, reflection supports better human-AI collaboration. By understanding and adapting to human preferences and feedback, AI systems can work more effectively alongside humans, leading to more productive and harmonious interactions.\", 'reflection': {'missing': 'Specific examples or case studies that illustrate the benefits of reflection in AI are missing. These would help to ground the abstract concepts in real-world applications and make the answer more compelling.', 'superfluous': 'Some parts of the answer may be slightly redundant, particularly the repeated emphasis on improvement and learning from past actions.'}, 'search_queries': ['examples of reflection in AI systems', 'case studies on reflective AI', 'benefits of reflective AI in real-world applications'], 'references': ['https://www.unite.ai/ais-inner-dialogue-how-self-reflection-enhances-chatbots-and-virtual-assistants/', 'https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection/', 'https://blog.langchain.dev/reflection-agents/', 'https://laxfed.dev/what-are-reflection-agents-68e49f13d90b', 'https://medium.com/stanford-d-school/reflecting-with-ai-a-tool-to-develop-human-intelligence-88cec86babf']}, 'id': 'call_a7zHIQgGQSPiCwAU8PE7Dz8E'}])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revised = revisor.respond(\n",
    "    [\n",
    "        HumanMessage(content=example_question),\n",
    "        initial,\n",
    "        ToolMessage(\n",
    "            tool_call_id=initial.tool_calls[0]['id'],\n",
    "            content=json.dumps(\n",
    "                tavily_tool.invoke(\n",
    "                    {\n",
    "                        'query': initial.tool_calls[0]['args']['search_queries'][0]\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'args': {'answer': \"Reflection in AI refers to an AI system's ability to monitor, analyze, and adapt its own processes and performance. This capability is essential for several reasons. Firstly, it allows AI systems to improve over time. By reflecting on past actions and outcomes, an AI can identify errors, learn from them, and adjust its behavior to avoid making the same mistakes in the future. This is particularly important in dynamic environments where conditions and requirements may change rapidly. Secondly, reflection enhances the transparency and explainability of AI systems. By being able to articulate why certain decisions were made or why particular actions were taken, AI systems can provide insights into their decision-making processes. This can increase trust and acceptance among users and stakeholders. Thirdly, reflection can contribute to ethical AI development. It enables AI systems to assess the implications of their actions and ensure they align with ethical guidelines and standards. Finally, reflection supports better human-AI collaboration. By understanding and adapting to human preferences and feedback, AI systems can work more effectively alongside humans, leading to more productive and harmonious interactions.\",\n",
       "   'reflection': {'missing': 'Specific examples or case studies that illustrate the benefits of reflection in AI are missing. These would help to ground the abstract concepts in real-world applications and make the answer more compelling.',\n",
       "    'superfluous': 'Some parts of the answer may be slightly redundant, particularly the repeated emphasis on improvement and learning from past actions.'},\n",
       "   'search_queries': ['examples of reflection in AI systems',\n",
       "    'case studies on reflective AI',\n",
       "    'benefits of reflective AI in real-world applications'],\n",
       "   'references': ['https://www.unite.ai/ais-inner-dialogue-how-self-reflection-enhances-chatbots-and-virtual-assistants/',\n",
       "    'https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection/',\n",
       "    'https://blog.langchain.dev/reflection-agents/',\n",
       "    'https://laxfed.dev/what-are-reflection-agents-68e49f13d90b',\n",
       "    'https://medium.com/stanford-d-school/reflecting-with-ai-a-tool-to-develop-human-intelligence-88cec86babf']},\n",
       "  'type': 'ReviseAnswer'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JsonOutputToolsParser().invoke(revised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tool Node\n",
    "Next, create a node to execute the tool calls. While we give the LLMs different schema names (and use those for validation), we want them both to route to the same tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_queries(search_queries: list[str], **kwargs):\n",
    "    '''Run the generated queries'''\n",
    "    return tavily_tool.batch([{'query': query} for query in search_queries])\n",
    "\n",
    "tool_node = ToolNode(\n",
    "    [\n",
    "        StructuredTool.from_function(run_queries, name=AnswerQuestion.__name__),\n",
    "        StructuredTool.from_function(run_queries, name=ReviseAnswer.__name__)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ITERATIONS = 5\n",
    "builder = MessageGraph()\n",
    "builder.add_node('draft', first_responder.respond)\n",
    "builder.add_node('execute_tools', tool_node)\n",
    "builder.add_node('revise', revisor.respond)\n",
    "\n",
    "builder.add_edge('draft', 'execute_tools') # draft -> execute_tools\n",
    "builder.add_edge('execute_tools', 'revise') # execute_tools -> revise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explicit loop\n",
    "def _get_num_iterations(state: List[BaseMessage]):\n",
    "    i = 0\n",
    "    for m in state[::-1]:\n",
    "        if m.type not in {'tool', 'ai'}:\n",
    "            break\n",
    "        i += 1\n",
    "    return i\n",
    "\n",
    "def event_loop(state: List[BaseMessage]) -> Literal['execute_tools', '__end__']:\n",
    "    # in our case we'll just stop after N plans\n",
    "    if _get_num_iterations(state) > MAX_ITERATIONS:\n",
    "        return END\n",
    "    return 'execute_tools'\n",
    "\n",
    "# revise -> execute_tools OR end\n",
    "builder.add_conditional_edges('revise', event_loop)\n",
    "builder.set_entry_point('draft')\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display.display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "How should we handle the climate crisis?\n",
      "RETRYING 0\n",
      "RETRYING 1\n",
      "RETRYING 2\n",
      "Step 1\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  AnswerQuestion (call_IJ82yHQTFFnwSt4SXuYhs7cN)\n",
      " Call ID: call_IJ82yHQTFFnwSt4SXuYhs7cN\n",
      "  Args:\n",
      "    answer: Addressing the climate crisis requires a multi-faceted approach that involves global cooperation, ambitious policy-making, technological innovation, and significant shifts in individual and collective behavior. Here are some key strategies to handle the climate crisis effectively:\n",
      "\n",
      "1. **International Cooperation**: Climate change is a global issue that requires coordinated international efforts. Agreements like the Paris Accord are critical, where countries commit to reducing greenhouse gas emissions and share technologies and strategies.\n",
      "\n",
      "2. **Policy and Regulation**: Governments need to implement stringent policies to limit carbon emissions. This includes setting carbon pricing, implementing emission trading systems, and enforcing regulations on industries to reduce their carbon footprint.\n",
      "\n",
      "3. **Renewable Energy**: Transitioning from fossil fuels to renewable energy sources such as wind, solar, and hydro is essential. Investment in renewable energy infrastructure and research is crucial to make these technologies more viable and widespread.\n",
      "\n",
      "4. **Technological Innovation**: Development and deployment of new technologies that can capture and store carbon, improve energy efficiency, and create sustainable alternatives to current practices are necessary. Innovations in electric vehicles, smart grids, and sustainable agriculture can significantly reduce emissions.\n",
      "\n",
      "5. **Public Awareness and Education**: Educating the public on the importance of reducing carbon footprints and adopting sustainable practices can drive change at the grassroots level. Campaigns to promote energy conservation, recycling, and sustainable consumption are vital.\n",
      "\n",
      "6. **Adaptation and Resilience**: Developing strategies to adapt to climate impacts that are already unavoidable is crucial. This includes building resilient infrastructure, protecting ecosystems, and preparing for climate-related disasters.\n",
      "\n",
      "7. **Financial Investment**: Significant financial investment from both the public and private sectors is needed to fund climate action initiatives. This includes financing renewable energy projects, supporting green technologies, and aiding developing countries in their climate adaptation and mitigation efforts.\n",
      "    reflection: {'missing': 'The answer could delve deeper into specific examples of successful climate policies and technological innovations. It should also address the challenges and barriers to implementing these strategies, such as political resistance, economic constraints, and social inequalities. Additionally, discussing the role of individual actions in more detail could make the answer more comprehensive.', 'superfluous': 'The general strategies presented are all relevant, but the answer might be too high-level and broad. Some points, like public awareness and education, could be condensed to focus more on actionable steps and specific case studies.', 'search_queries': ['successful climate policies examples', 'barriers to climate policy implementation', 'technological innovations in renewable energy', 'role of individual actions in climate change mitigation']}\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for AnswerQuestionSchema\nsearch_queries\n  field required (type=value_error.missing)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m events \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m      2\u001b[0m     [HumanMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHow should we handle the climate crisis?\u001b[39m\u001b[38;5;124m'\u001b[39m)],\n\u001b[1;32m      3\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m )\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(events):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m     step[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpretty_print()\n",
      "File \u001b[0;32m~/anaconda3/envs/pinegap/lib/python3.10/site-packages/langgraph/pregel/__init__.py:876\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[1;32m    869\u001b[0m done, inflight \u001b[38;5;241m=\u001b[39m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mwait(\n\u001b[1;32m    870\u001b[0m     futures,\n\u001b[1;32m    871\u001b[0m     return_when\u001b[38;5;241m=\u001b[39mconcurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mFIRST_EXCEPTION,\n\u001b[1;32m    872\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m    873\u001b[0m )\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[0;32m--> 876\u001b[0m \u001b[43m_panic_or_proceed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minflight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# combine pending writes from all tasks\u001b[39;00m\n\u001b[1;32m    879\u001b[0m pending_writes \u001b[38;5;241m=\u001b[39m deque[\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]()\n",
      "File \u001b[0;32m~/anaconda3/envs/pinegap/lib/python3.10/site-packages/langgraph/pregel/__init__.py:1422\u001b[0m, in \u001b[0;36m_panic_or_proceed\u001b[0;34m(done, inflight, step)\u001b[0m\n\u001b[1;32m   1420\u001b[0m             inflight\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[1;32m   1421\u001b[0m         \u001b[38;5;66;03m# raise the exception\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inflight:\n\u001b[1;32m   1425\u001b[0m     \u001b[38;5;66;03m# if we got here means we timed out\u001b[39;00m\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m inflight:\n\u001b[1;32m   1427\u001b[0m         \u001b[38;5;66;03m# cancel all pending tasks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pinegap/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/anaconda3/envs/pinegap/lib/python3.10/site-packages/langgraph/pregel/retry.py:66\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy)\u001b[0m\n\u001b[1;32m     64\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pinegap/lib/python3.10/site-packages/langchain_core/runnables/base.py:2493\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2489\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[1;32m   2490\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2491\u001b[0m )\n\u001b[1;32m   2492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2493\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2494\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2495\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/anaconda3/envs/pinegap/lib/python3.10/site-packages/langgraph/utils.py:89\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m     83\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(var_child_runnable_config\u001b[38;5;241m.\u001b[39mset, config)\n\u001b[1;32m     84\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     85\u001b[0m         {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m: config}\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m accepts_config(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc)\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs\n\u001b[1;32m     88\u001b[0m     )\n\u001b[0;32m---> 89\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/anaconda3/envs/pinegap/lib/python3.10/site-packages/langgraph/prebuilt/tool_node.py:68\u001b[0m, in \u001b[0;36mToolNode._func\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ToolMessage(\n\u001b[1;32m     64\u001b[0m         content\u001b[38;5;241m=\u001b[39mstr_output(output), name\u001b[38;5;241m=\u001b[39mcall[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m], tool_call_id\u001b[38;5;241m=\u001b[39mcall[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     65\u001b[0m     )\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m---> 68\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39mexecutor\u001b[38;5;241m.\u001b[39mmap(run_one, message\u001b[38;5;241m.\u001b[39mtool_calls)]\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/anaconda3/envs/pinegap/lib/python3.10/concurrent/futures/_base.py:621\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m~/anaconda3/envs/pinegap/lib/python3.10/concurrent/futures/_base.py:319\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 319\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    321\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m~/anaconda3/envs/pinegap/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/anaconda3/envs/pinegap/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pinegap/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/anaconda3/envs/pinegap/lib/python3.10/site-packages/langchain_core/runnables/config.py:499\u001b[0m, in \u001b[0;36mContextThreadPoolExecutor.map.<locals>._wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m--> 499\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontexts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pinegap/lib/python3.10/site-packages/langgraph/prebuilt/tool_node.py:62\u001b[0m, in \u001b[0;36mToolNode._func.<locals>.run_one\u001b[0;34m(call)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_one\u001b[39m(call: ToolCall):\n\u001b[0;32m---> 62\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtools_by_name\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43margs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ToolMessage(\n\u001b[1;32m     64\u001b[0m         content\u001b[38;5;241m=\u001b[39mstr_output(output), name\u001b[38;5;241m=\u001b[39mcall[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m], tool_call_id\u001b[38;5;241m=\u001b[39mcall[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     65\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/pinegap/lib/python3.10/site-packages/langchain_core/tools.py:260\u001b[0m, in \u001b[0;36mBaseTool.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28minput\u001b[39m: Union[\u001b[38;5;28mstr\u001b[39m, Dict],\n\u001b[1;32m    256\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    258\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    259\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m--> 260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pinegap/lib/python3.10/site-packages/langchain_core/tools.py:417\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, **kwargs)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_validation_error:\n\u001b[0;32m--> 417\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_validation_error, \u001b[38;5;28mbool\u001b[39m):\n\u001b[1;32m    419\u001b[0m         observation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTool input validation error\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/pinegap/lib/python3.10/site-packages/langchain_core/tools.py:406\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m    405\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[0;32m--> 406\u001b[0m parsed_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m tool_args, tool_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_args_and_kwargs(parsed_input)\n\u001b[1;32m    408\u001b[0m observation \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    409\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run, \u001b[38;5;241m*\u001b[39mtool_args, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtool_kwargs\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run, \u001b[38;5;241m*\u001b[39mtool_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtool_kwargs)\n\u001b[1;32m    414\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/pinegap/lib/python3.10/site-packages/langchain_core/tools.py:304\u001b[0m, in \u001b[0;36mBaseTool._parse_input\u001b[0;34m(self, tool_input)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m input_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43minput_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    306\u001b[0m             k: \u001b[38;5;28mgetattr\u001b[39m(result, k)\n\u001b[1;32m    307\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdict()\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    308\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m tool_input\n\u001b[1;32m    309\u001b[0m         }\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tool_input\n",
      "File \u001b[0;32m~/anaconda3/envs/pinegap/lib/python3.10/site-packages/pydantic/v1/main.py:526\u001b[0m, in \u001b[0;36mBaseModel.parse_obj\u001b[0;34m(cls, obj)\u001b[0m\n\u001b[1;32m    524\u001b[0m         exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m expected dict not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ValidationError([ErrorWrapper(exc, loc\u001b[38;5;241m=\u001b[39mROOT_KEY)], \u001b[38;5;28mcls\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m--> 526\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pinegap/lib/python3.10/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for AnswerQuestionSchema\nsearch_queries\n  field required (type=value_error.missing)"
     ]
    }
   ],
   "source": [
    "events = graph.stream(\n",
    "    [HumanMessage(content='How should we handle the climate crisis?')],\n",
    "    stream_mode='values'\n",
    ")\n",
    "\n",
    "for i, step in enumerate(events):\n",
    "    print(f'Step {i}')\n",
    "    step[-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "Observations to consider when adapting a workflow\n",
    "\n",
    "1. This agent trades off execution time for quality. It explicitly forces the agent to critique and revise the output over several steps, which usually (not always) increases the response quality but takes much longer to return a final answer.\n",
    "2. The 'reflections' can be paired with additional external feedback (such as validators), to further guide the actor.\n",
    "3. In the paper, 1 environment (AlfWorld) uses external memory. It does this by storing summaries of the reflections to an external store and using them in subsequent trials/invocations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinegap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
