{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STORM\n",
    "### Synthesis of Topic Outlines through Retrieval and Multi-perspective question asking.\n",
    "\n",
    "Research assistant that extends the idea of 'outline-driven RAG' for richer article generation.\n",
    "\n",
    "It applies two main insights to produce more organized and comprehensive articles:\n",
    "1. Creating an outline (planning) by querying similar topics helps improve coverage.\n",
    "2. Multi-perspective, grounded (in search) conversation simulation helps increase the reference count and information density."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview\n",
    "1. Generate initial outline + survey related subjects\n",
    "2. Identify distiinct perspectives\n",
    "3. \"Interview subject matter experts\" (role-playing LLMs)\n",
    "4. Refine outline (using references)\n",
    "5. Write sections, then write article\n",
    "\n",
    "The expert interviews stage occurs between the role-playing article writer and a research expert. The \"expert\" is able to query external knowledge and respond to pointed questions, saving cited sources to a vectorstore so that the later refinement stages can synthesize the full article.\n",
    "\n",
    "Hyperparameters to restrict the potentially infinite research breadth:\n",
    "- N: number of perspectives to survey\n",
    "- M: Max number of conversation turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select LLMs\n",
    "We will have a faster LLM to do most of the work, but a slower, long-context model to distill the conversations and write the final report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "FAST_LLM = ChatOpenAI(model='gpt-3.5-turbo')\n",
    "GOOD_LLM = ChatOpenAI(model='gpt-4o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Initial Outline\n",
    "For many topics, your LLM may have an initial idea of the important and related topics. We can generate an initial outline to be referred after our research. Below, we will use our 'fast' llm to generate the outline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "direct_gen_outline_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            'system',\n",
    "            'You are a an experienced equity research analyst. Write an outline for an analysis report about a user-provided topic. Be comprehensive and specific.'\n",
    "        ),\n",
    "        ('user', '{topic}')\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "class Subsection(BaseModel):\n",
    "    subsection_title: str = Field(..., title='Title of the subsection')\n",
    "    description: str = Field(..., title='Content of the subsection')\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        return f'### {self.subsection_title}\\n\\n{self.description}'.strip()\n",
    "    \n",
    "\n",
    "class Section(BaseModel):\n",
    "    section_title: str = Field(..., title='Title of the section')\n",
    "    description: str = Field(..., title='Content of the section')\n",
    "    subsections: Optional[List[Subsection]] = Field(default=None, title='Titles and descriptions for each subsection of the analysis report.')\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        subsections = '\\n\\n'.join(f'### {subsection.subsection_title}\\n\\n{subsection.description}' for subsection in self.subsections or [])\n",
    "        return f'## {self.section_title}\\n\\n{self.description}\\n\\n{subsections}'.strip()\n",
    "    \n",
    "\n",
    "class Outline(BaseModel):\n",
    "    page_title: str = Field(..., title='Title of the Report')\n",
    "    sections: List[Section] = Field(\n",
    "        default_factory=list,\n",
    "        title='Titles and descriptions for each section of the Report page.'\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        sections = '\\n\\n'.join(section.as_str for section in self.sections)\n",
    "        return f'# {self.page_title}\\n\\n{sections}'.strip()\n",
    "    \n",
    "generate_outline_direct = direct_gen_outline_prompt | FAST_LLM.with_structured_output(Outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_topic = 'Impact on silicon industry due to the China Taiwan war'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_outline = generate_outline_direct.invoke({'topic': example_topic})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Impact on Silicon Industry Due to the China-Taiwan War\n",
      "\n",
      "## Introduction\n",
      "\n",
      "Brief overview of the China-Taiwan conflict and its potential implications on the silicon industry.\n",
      "\n",
      "## Current State of the Silicon Industry\n",
      "\n",
      "Overview of the global silicon industry, key players, market size, and growth trends.\n",
      "\n",
      "## Key Suppliers in Taiwan\n",
      "\n",
      "Analysis of Taiwan's role in the silicon industry, including key suppliers and their market share.\n",
      "\n",
      "## Impact of Conflict on Supply Chain\n",
      "\n",
      "Discussion on how the China-Taiwan conflict could disrupt the silicon supply chain and production.\n",
      "\n",
      "## Geopolitical Factors\n",
      "\n",
      "Analysis of geopolitical factors influencing the silicon industry amidst the China-Taiwan conflict.\n",
      "\n",
      "## Market Reactions\n",
      "\n",
      "Evaluation of the market reactions to the conflict, including stock price movements and investor sentiment.\n",
      "\n",
      "## Potential Scenarios and Risks\n",
      "\n",
      "Assessment of potential scenarios and risks for the silicon industry in the event of escalating tensions.\n"
     ]
    }
   ],
   "source": [
    "print(initial_outline.as_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expand topics\n",
    "While language models do store some Wikipedia-like knowledge in their parameters, you will get better results by incorporating relevant and recent information using a search engine.\n",
    "\n",
    "We will start our search by generating a list of related topics, sourced from Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_related_topics_prompt = ChatPromptTemplate.from_template(\n",
    "    '''I'm writing a Wikipedia page for a topic mentioned below. Please identify and recommend some Wikipedia pages on closely related subjects.\n",
    "    I'm looking for examples that provide insights into interesting aspects commonly associated with this topic, or examples that help me understand the typical content and structure included in Wikipedia pages for similar topics.\n",
    "    Please list as many subjects and urls as you can.\n",
    "\n",
    "    Topic of interest: {topic}''')\n",
    "\n",
    "class RelatedSubjects(BaseModel):\n",
    "    topics: List[str] = Field(description='Comprehensive list of related subjects as background research')\n",
    "\n",
    "expand_chain = gen_related_topics_prompt | FAST_LLM.with_structured_output(RelatedSubjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RelatedSubjects(topics=['Silicon Industry', 'China Taiwan Conflict', 'Economic Impact', 'Global Supply Chain', 'Technology Industry', 'Trade Relations', 'Geopolitics'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_subjects = await expand_chain.ainvoke({'topic': example_topic})\n",
    "related_subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Perspectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinegap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
